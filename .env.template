###############################################################################
# NOTE: With default settings Cognee only needs an OpenAI LLM_API_KEY to be set.
#       The rest of the settings don't have to be set.
#       Default relational database: SQLite
#       Default vector database   : LanceDB
#       Default graph database    : Kuzu
#
#       These default databases are all file-based, so no extra setup is needed
#       for local use. The data by default will be stored in your .venv
###############################################################################

################################################################################
#  üß† LLM Settings
################################################################################
# Currently we support BAML and Instructor(using litellm) for structured outputs
STRUCTURED_OUTPUT_FRAMEWORK="instructor"

LLM_API_KEY="your_api_key"
LLM_MODEL="openai/gpt-5-mini"
LLM_PROVIDER="openai"
LLM_ENDPOINT=""
LLM_API_VERSION=""
LLM_MAX_TOKENS="16384"
# Instructor's modes determine how structured data is requested from and extracted from LLM responses
# You can change this type (i.e. mode) via this env variable
# Each LLM has its own default value, e.g. gpt-5 models have "json_schema_mode"
LLM_INSTRUCTOR_MODE=""

EMBEDDING_PROVIDER="openai"
EMBEDDING_MODEL="openai/text-embedding-3-large"
EMBEDDING_ENDPOINT=""
EMBEDDING_API_VERSION=""
EMBEDDING_DIMENSIONS=3072
EMBEDDING_MAX_TOKENS=8191
EMBEDDING_BATCH_SIZE=36
# If embedding key is not provided same key set for LLM_API_KEY will be used
#EMBEDDING_API_KEY="your_api_key"


# If using BAML structured output these env variables will be used
BAML_LLM_PROVIDER=openai
BAML_LLM_MODEL="gpt-5-mini"
BAML_LLM_ENDPOINT=""
BAML_LLM_API_KEY="your_api_key"
BAML_LLM_API_VERSION=""


################################################################################
#  üìÇ ROOT DIRECTORY FOR DATABASES
################################################################################
# Set up the Cognee system directory. Cognee will store system files and databases here.
# Useful for setting root directory inside docker and also to avoid storing the databases in .venv
# DATA_ROOT_DIRECTORY='/Users/<user>/Desktop/cognee/.cognee_data/'
# SYSTEM_ROOT_DIRECTORY='/Users/<user>/Desktop/cognee/.cognee_system/'

################################################################################
# ‚òÅÔ∏è Storage Backend Settings
################################################################################
# Configure storage backend (local filesystem or S3)
# STORAGE_BACKEND="local"  # Default: uses local filesystem
#
# -- To switch to S3 storage, uncomment and fill these: ---------------------
# STORAGE_BACKEND="s3"
# STORAGE_BUCKET_NAME="your-bucket-name"
# AWS_REGION="us-east-1"
# AWS_ACCESS_KEY_ID="your-access-key"
# AWS_SECRET_ACCESS_KEY="your-secret-key"
#
# -- S3 Root Directories (optional) -----------------------------------------
# DATA_ROOT_DIRECTORY="s3://your-bucket/cognee/data"
# SYSTEM_ROOT_DIRECTORY="s3://your-bucket/cognee/system"
#
# -- Cache Directory (auto-configured for S3) -------------------------------
# When STORAGE_BACKEND=s3, cache automatically uses S3: s3://BUCKET/cognee/cache
# To override the automatic S3 cache location, uncomment:
# CACHE_ROOT_DIRECTORY="s3://your-bucket/cognee/cache"

################################################################################
# üóÑÔ∏è Relational database settings
################################################################################

DB_PROVIDER="sqlite"
DB_NAME=cognee_db

# -- To switch to Postgres / PGVector, uncomment and fill these: -------------
#DB_PROVIDER=postgres
#DB_NAME=cognee_db
# To use Postgres with the Cognee backend in Docker compose use the following instead: DB_HOST=host.docker.internal
#DB_HOST=127.0.0.1
#DB_PORT=5432
#DB_USERNAME=cognee
#DB_PASSWORD=cognee

################################################################################
# üï∏Ô∏è Graph Database settings
################################################################################

# Default (local file-based)
GRAPH_DATABASE_PROVIDER="kuzu"
# Handler for multi-user access control mode, it handles how should the mapping/creation of separate DBs be handled per Cognee dataset
GRAPH_DATASET_DATABASE_HANDLER="kuzu"

# -- To switch to Remote Kuzu uncomment and fill these: -------------------------------------------------------------
#GRAPH_DATABASE_PROVIDER="kuzu"
#GRAPH_DATABASE_PROVIDER="kuzu-remote"
#GRAPH_DATABASE_URL="http://localhost:8000"
#GRAPH_DATABASE_USERNAME=XXX
#GRAPH_DATABASE_PASSWORD=YYY

# -- To switch to Neo4j uncomment and fill these: -------------------------------------------------------------------
#GRAPH_DATABASE_PROVIDER="neo4j"
#GRAPH_DATABASE_URL=bolt://localhost:7687
#GRAPH_DATABASE_NAME="neo4j"
#GRAPH_DATABASE_USERNAME=neo4j
#GRAPH_DATABASE_PASSWORD=localneo4j

################################################################################
#  üìê Vector Database settings
################################################################################

# Supported providers: pgvector | qdrant | weaviate | milvus | lancedb | chromadb
VECTOR_DB_PROVIDER="lancedb"
# Not needed if a cloud vector database is not used
VECTOR_DB_URL=
VECTOR_DB_KEY=
# Handler for multi-user access control mode, it handles how should the mapping/creation of separate DBs be handled per Cognee dataset
VECTOR_DATASET_DATABASE_HANDLER="lancedb"

################################################################################
# üß© Ontology resolver settings
################################################################################

# -- Ontology resolver params --------------------------------------
# ONTOLOGY_RESOLVER=rdflib  # Default: uses rdflib and owl file to read ontology structures
# MATCHING_STRATEGY=fuzzy # Default: uses fuzzy matching with 80% similarity threshold
# ONTOLOGY_FILE_PATH=YOUR_FULL_FULE_PATH # Default: empty
# To add ontology resolvers, either set them as it is set in ontology_example or add full_path and settings as envs.

################################################################################
#  üîÑ  MIGRATION (RELATIONAL ‚Üí GRAPH) SETTINGS
################################################################################

MIGRATION_DB_PATH="/path/to/migration/directory"
MIGRATION_DB_NAME="migration_database.sqlite"
MIGRATION_DB_PROVIDER="sqlite"

# -- Postgres-specific migration params --------------------------------------
# MIGRATION_DB_USERNAME=cognee
# MIGRATION_DB_PASSWORD=cognee
# MIGRATION_DB_HOST="127.0.0.1"
# MIGRATION_DB_PORT=5432

################################################################################
# üîí Security Settings
################################################################################

################################################################################
# JWT Security (REQUIRED for production)
################################################################################
# Generate secrets with: python -c "import secrets; print(secrets.token_urlsafe(64))"
# These secrets must be at least 32 characters and NOT weak defaults like "super_secret"
FASTAPI_USERS_JWT_SECRET=
FASTAPI_USERS_RESET_PASSWORD_TOKEN_SECRET=
FASTAPI_USERS_VERIFICATION_TOKEN_SECRET=

################################################################################
# Rate Limiting - Authentication
################################################################################
# Enable/disable auth rate limiting (default: true)
AUTH_RATE_LIMIT_ENABLED=true

# Login rate limits (default: 5 requests per 300 seconds)
AUTH_RATE_LIMIT_LOGIN_REQUESTS=5
AUTH_RATE_LIMIT_LOGIN_WINDOW=300

# OAuth authorize rate limits (default: 10 requests per 60 seconds)
AUTH_RATE_LIMIT_OAUTH_REQUESTS=10
AUTH_RATE_LIMIT_OAUTH_WINDOW=60

# OAuth callback rate limits (default: 5 requests per 60 seconds)
AUTH_RATE_LIMIT_CALLBACK_REQUESTS=5
AUTH_RATE_LIMIT_CALLBACK_WINDOW=60

################################################################################
# OAuth State Storage (Kubernetes/Multi-Instance)
################################################################################
# For single-instance deployments, leave unset (uses in-memory storage)
# For Kubernetes/multi-pod deployments, set Redis URL:
# OAUTH_STATE_REDIS_URL=redis://redis-host:6379/0

# State TTL in seconds (default: 600 = 10 minutes)
# OAUTH_STATE_TTL=600

################################################################################
# SSRF Protection
################################################################################
# Enable/disable SSRF protection (default: true)
SSRF_PROTECTION_ENABLED=true

# Allow fetching from private/internal IP ranges (default: false)
# WARNING: Only set to true in trusted environments
ALLOW_PRIVATE_URLS=false

# When set to false don't allow adding of local system files to Cognee. Should be set to False when Cognee is used as a backend.
ACCEPT_LOCAL_FILE_PATH=True

# When set to false don't allow HTTP requests to be sent from Cognee.
# This protects against Server Side Request Forgery when proper infrastructure is not in place.
ALLOW_HTTP_REQUESTS=True

# When set to false don't allow cypher search to be used in Cognee.
ALLOW_CYPHER_QUERY=True

# When set to False errors during data processing will be returned as info but not raised to allow handling of faulty documents
RAISE_INCREMENTAL_LOADING_ERRORS=True

# When set to True, the Cognee backend will require authentication for requests to the API.
# If you're disabling this, make sure to also disable ENABLE_BACKEND_ACCESS_CONTROL.
REQUIRE_AUTHENTICATION=False

# Set this variable to True to enforce usage of backend access control for Cognee
# Note: This is only currently supported by the following databases:
#       Relational: SQLite, Postgres
#       Vector: LanceDB
#       Graph: KuzuDB
#
# It enforces creation of databases per Cognee user + dataset. Does not work with some graph and database providers.
# Disable mode when using not supported graph/vector databases.
ENABLE_BACKEND_ACCESS_CONTROL=True

################################################################################
# üîê OIDC/Keycloak Authentication Settings
################################################################################

# Enable OIDC authentication (Keycloak federated with Microsoft EntraID, Google, GitHub)
OIDC_ENABLED=false

# Keycloak OIDC Configuration
OIDC_PROVIDER_NAME=keycloak
OIDC_CLIENT_ID=cognee
OIDC_CLIENT_SECRET=your-client-secret
# .well-known/openid-configuration endpoint URL
OIDC_SERVER_METADATA_URL=https://keycloak.example.com/realms/cognee/.well-known/openid-configuration

# OAuth callback URL (must match Keycloak client configuration)
OIDC_BASE_URL=http://localhost:8000
OIDC_REDIRECT_URI=http://localhost:8000/api/v1/auth/oidc/callback

# Scopes to request from OIDC provider
OIDC_SCOPES="openid profile email"

# Group Mapping Configuration
# Name of the claim containing group memberships in the OIDC token
OIDC_GROUP_CLAIM=groups
# Path to JSON file with group-to-role mappings (optional)
OIDC_GROUP_MAPPING_FILE=/path/to/group_mappings.json
# Or provide mappings directly as JSON string (alternative to file)
# OIDC_GROUP_MAPPING_JSON='{"IT-Admins": ["admin"], "Data-Scientists": ["editor", "reader"]}'
# Default role for users without matching group mappings
OIDC_DEFAULT_ROLE=viewer

# JIT (Just-In-Time) User Provisioning
OIDC_AUTO_PROVISION_USERS=true
# Auto-assign to specific tenant (optional, leave empty for per-user tenants)
OIDC_AUTO_ASSIGN_TENANT=
# Create tenant based on email domain (e.g., user@example.com -> org-example.com)
OIDC_TENANT_FROM_EMAIL_DOMAIN=true

# Role Sync Settings
# "additive" = only add roles from current groups (default)
# "sync" = remove roles not in current groups
OIDC_ROLE_SYNC_MODE=additive
# Remove roles not mapped from current OIDC groups
OIDC_REMOVE_UNMATCHED_ROLES=false

# SSL/TLS settings
OIDC_VERIFY_SSL=true

################################################################################
# ‚òÅÔ∏è Cloud Sync Settings
################################################################################

# Cognee Cloud API settings for syncing data to/from cloud infrastructure
COGNEE_CLOUD_API_URL="http://localhost:8001"
COGNEE_CLOUD_AUTH_TOKEN="your-api-key"

################################################################################
# UI Settings
################################################################################

# URL where the frontend is served, defaults to http://localhost:3000
UI_APP_URL=http://localhost:3000

################################################################################
#  üõ†Ô∏è DEV Settings
################################################################################

ENV="local"

TOKENIZERS_PARALLELISM="false"

# LITELLM Logging Level. Set to quiet down logging
LITELLM_LOG="ERROR"

# Set this environment variable to disable sending telemetry data
# TELEMETRY_DISABLED=1

# Default User Configuration
# DEFAULT_USER_EMAIL=""
# DEFAULT_USER_PASSWORD=""

################################################################################
#  üìÇ AWS Settings
################################################################################

#AWS_REGION=""
#AWS_ENDPOINT_URL=""
#AWS_ACCESS_KEY_ID=""
#AWS_SECRET_ACCESS_KEY=""
#AWS_SESSION_TOKEN=""

------------------------------- END OF POSSIBLE SETTINGS -------------------------------


###############################################################################
# üß™  EXAMPLE OVERRIDES (commented out)
###############################################################################
# The blocks below show how to configure alternative providers.
# Uncomment + fill values to switch.

########## Azure OpenAI #######################################################
#LLM_MODEL="azure/gpt-5-mini"
#LLM_ENDPOINT="https://DNS.azure.com/openai/deployments/gpt-5-mini"
#LLM_API_KEY="<<TALK TO YOUR AZURE GUY"
#LLM_API_VERSION="2024-12-01-preview"

## llm api version might not be relevant
#LLM_MAX_TOKENS="16384"

#EMBEDDING_MODEL="azure/text-embedding-3-large"
#EMBEDDING_ENDPOINT="https://DNS.openai.azure.com/openai/deployments/text-embedding-3-large"
#EMBEDDING_API_KEY="<<TALK TO YOUR AZURE GUY>"
#EMBEDDING_API_VERSION="2024-12-01-preview"
#EMBEDDING_DIMENSIONS=3072
#EMBEDDING_MAX_TOKENS=8191

########## Local LLM via Ollama ###############################################


#LLM_API_KEY ="ollama"
#LLM_MODEL="llama3.1:8b"
#LLM_PROVIDER="ollama"
#LLM_ENDPOINT="http://localhost:11434/v1"
#EMBEDDING_PROVIDER="ollama"
#EMBEDDING_MODEL="nomic-embed-text:latest"
#EMBEDDING_ENDPOINT="http://localhost:11434/api/embed"
#EMBEDDING_DIMENSIONS=768
#HUGGINGFACE_TOKENIZER="nomic-ai/nomic-embed-text-v1.5"

########## OpenRouter (also free) #########################################################

#LLM_API_KEY="<<go-get-one-yourself"
#LLM_PROVIDER="custom"
#LLM_MODEL="openrouter/google/gemini-2.0-flash-lite-preview-02-05:free"
#LLM_ENDPOINT="https://openrouter.ai/api/v1"

########## DeepInfra ##########################################################

#LLM_API_KEY="<<>>"
#LLM_PROVIDER="custom"
#LLM_MODEL="deepinfra/meta-llama/Meta-Llama-3-8B-Instruct"
#LLM_ENDPOINT="https://api.deepinfra.com/v1/openai"

#EMBEDDING_PROVIDER="openai"
#EMBEDDING_API_KEY="<<>>"
#EMBEDDING_MODEL="deepinfra/BAAI/bge-base-en-v1.5"
#EMBEDDING_ENDPOINT=""
#EMBEDDING_API_VERSION=""
#EMBEDDING_DIMENSIONS=3072
#EMBEDDING_MAX_TOKENS=8191


########## Release Test ###############################################

#LLM_API_KEY="..."

#OPENAI_API_KEY="..."

#MIGRATION_DB_PATH="~/Downloads/"
#MIGRATION_DB_NAME="Chinook_Sqlite.sqlite"
#MIGRATION_DB_PROVIDER="sqlite"

#GRAPH_DATABASE_URL="bolt://54.246.89.112:7687"
#GRAPH_DATABASE_USERNAME="neo4j"
#GRAPH_DATABASE_PASSWORD="pleaseletmein"
