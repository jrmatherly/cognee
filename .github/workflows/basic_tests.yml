name: Reusable Basic Tests

on:
  workflow_call:
    inputs:
      python-version:
        required: false
        type: string
        default: '3.11.x'
    secrets:
      LLM_PROVIDER:
        required: true
      LLM_MODEL:
        required: true
      LLM_ENDPOINT:
        required: true
      LLM_API_KEY:
        required: true
      LLM_API_VERSION:
        required: true
      EMBEDDING_PROVIDER:
        required: true
      EMBEDDING_MODEL:
        required: true
      EMBEDDING_ENDPOINT:
        required: true
      EMBEDDING_API_KEY:
        required: true
      EMBEDDING_API_VERSION:
        required: true

env:
  RUNTIME__LOG_LEVEL: ERROR
  ENV: 'dev'
  # JWT secrets for testing (safe to use static value in CI since not exposed)
  # Generate for production with: python -c "import secrets; print(secrets.token_urlsafe(64))"
  FASTAPI_USERS_JWT_SECRET: "ci_test_jwt_secret_not_for_production_use_64_chars_minimum_aaaa"
  FASTAPI_USERS_RESET_PASSWORD_TOKEN_SECRET: "ci_test_reset_secret_not_for_production_use_64_chars_minimum_aa"
  FASTAPI_USERS_VERIFICATION_TOKEN_SECRET: "ci_test_verify_secret_not_for_production_use_64_chars_minimum_aa"

jobs:

  lint:
    name: Run Linting
    runs-on: ubuntu-22.04
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cognee Setup
        uses: ./.github/actions/cognee_setup
        with:
          python-version: ${{ inputs.python-version }}

      - name: Run Linting
        uses: astral-sh/ruff-action@v2

  format-check:
    name: Run Formatting Check
    runs-on: ubuntu-22.04
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cognee Setup
        uses: ./.github/actions/cognee_setup
        with:
          python-version: ${{ inputs.python-version }}

      - name: Run Formatting Check
        uses: astral-sh/ruff-action@v2
        with:
          args: "format --check"

  unit-tests:
    name: Run Unit Tests
    runs-on: ubuntu-22.04
    env:
      ENV: 'dev'
      LLM_PROVIDER: openai
      LLM_MODEL: ${{ secrets.LLM_MODEL }}
      LLM_ENDPOINT: ${{ secrets.LLM_ENDPOINT }}
      LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
      LLM_API_VERSION: ${{ secrets.LLM_API_VERSION }}

      EMBEDDING_PROVIDER: openai
      EMBEDDING_MODEL: ${{ secrets.EMBEDDING_MODEL }}
      EMBEDDING_ENDPOINT: ${{ secrets.EMBEDDING_ENDPOINT }}
      EMBEDDING_API_KEY: ${{ secrets.EMBEDDING_API_KEY }}
      EMBEDDING_API_VERSION: ${{ secrets.EMBEDDING_API_VERSION }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cognee Setup
        uses: ./.github/actions/cognee_setup
        with:
          python-version: ${{ inputs.python-version }}

      - name: Run Unit Tests
        run: uv run pytest cognee/tests/unit/

  integration-tests:
    name: Run Integration Tests
    runs-on: ubuntu-22.04
    env:
      ENV: 'dev'
      LLM_PROVIDER: openai
      LLM_MODEL: ${{ secrets.LLM_MODEL }}
      LLM_ENDPOINT: ${{ secrets.LLM_ENDPOINT }}
      LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
      LLM_API_VERSION: ${{ secrets.LLM_API_VERSION }}
      EMBEDDING_MODEL: ${{ secrets.EMBEDDING_MODEL }}
      EMBEDDING_ENDPOINT: ${{ secrets.EMBEDDING_ENDPOINT }}
      EMBEDDING_API_KEY: ${{ secrets.EMBEDDING_API_KEY }}
      EMBEDDING_API_VERSION: ${{ secrets.EMBEDDING_API_VERSION }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cognee Setup
        uses: ./.github/actions/cognee_setup
        with:
          python-version: ${{ inputs.python-version }}
          extra-dependencies: "scraping"

      - name: Run Integration Tests
        run: uv run pytest cognee/tests/integration/

  simple-examples:
    name: Run Simple Examples
    runs-on: ubuntu-22.04
    env:
      ENV: 'dev'
      LLM_PROVIDER: openai
      LLM_MODEL: ${{ secrets.LLM_MODEL }}
      LLM_ENDPOINT: ${{ secrets.LLM_ENDPOINT }}
      LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
      LLM_API_VERSION: ${{ secrets.LLM_API_VERSION }}

      EMBEDDING_PROVIDER: openai
      EMBEDDING_MODEL: ${{ secrets.EMBEDDING_MODEL }}
      EMBEDDING_ENDPOINT: ${{ secrets.EMBEDDING_ENDPOINT }}
      EMBEDDING_API_KEY: ${{ secrets.EMBEDDING_API_KEY }}
      EMBEDDING_API_VERSION: ${{ secrets.EMBEDDING_API_VERSION }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cognee Setup
        uses: ./.github/actions/cognee_setup
        with:
          python-version: ${{ inputs.python-version }}

      - name: Run Simple Examples
        run: uv run python ./examples/python/simple_example.py

  simple-examples-baml:
    name: Run Simple Examples BAML
    runs-on: ubuntu-22.04
    env:
      ENV: 'dev'
      STRUCTURED_OUTPUT_FRAMEWORK: "BAML"
      BAML_LLM_PROVIDER: openai
      BAML_LLM_MODEL: ${{ secrets.OPENAI_MODEL }}
      BAML_LLM_ENDPOINT: ${{ secrets.OPENAI_ENDPOINT }}
      BAML_LLM_API_KEY: ${{ secrets.OPENAI_API_KEY }}
#      BAML_LLM_API_VERSION: ${{ secrets.LLM_API_VERSION }}

      LLM_PROVIDER: openai
      LLM_MODEL: ${{ secrets.LLM_MODEL }}
      LLM_ENDPOINT: ${{ secrets.LLM_ENDPOINT }}
      LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
      LLM_API_VERSION: ${{ secrets.LLM_API_VERSION }}

      EMBEDDING_PROVIDER: openai
      EMBEDDING_MODEL: ${{ secrets.EMBEDDING_MODEL }}
      EMBEDDING_ENDPOINT: ${{ secrets.EMBEDDING_ENDPOINT }}
      EMBEDDING_API_KEY: ${{ secrets.EMBEDDING_API_KEY }}
      EMBEDDING_API_VERSION: ${{ secrets.EMBEDDING_API_VERSION }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cognee Setup
        uses: ./.github/actions/cognee_setup
        with:
          python-version: ${{ inputs.python-version }}
          extra-dependencies: "baml"

      - name: Run Simple Examples
        run: uv run python ./examples/python/simple_example.py
